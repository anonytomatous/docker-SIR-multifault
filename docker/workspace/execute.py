"""
execute.py (should be run in docker environment)

extract failing tests result & coverage data
"""

import os
import sys
import re
import glob
import time
import subprocess
import shlex
import shutil
import argparse
import logging
import json
from itertools import combinations
from binaryornot.check import is_binary
from preprocess import split_test_cases, clean_faultseed, modify_makefile, add_faultseed_to_source, add_longlong_definition
from util import sort_string_by_number, get_test_cases, get_test_number
from faulty_components import extract_faulty_lines

# 1. compare original version vs. faulty version and find faulty line

# 2. clean up test suite and collect pass/fail result

# 3. construct multi-fault dataset (merge seeded fault lines and check test pass/fail result)


class Version:
    """
    A specific version of a C program with original code (no failing tests) and artificial faulty codes generated by a set of seeded faults
    """

    def __init__(self, project, version):

        root_path = f'/root/{project}'
        seeded_path = f'{root_path}/versions.alt/versions.seeded/{version}'
        output_path = f'{root_path}/outputs'
        cov_path = f'/root/coverage_files/{project}/{version}'
        test_result_path = f'/root/failing_tests/{project}'
        fault_map_path = f'{root_path}/info/{version}'
        test_script_path = f'{root_path}/testplans.alt/test_{version}'
        fault_seeds_path = os.path.join(seeded_path, 'FaultSeeds.h')

        assert os.path.exists(fault_seeds_path)

        # preprocess
        os.makedirs(test_result_path, exist_ok=True)
        os.makedirs(cov_path, exist_ok=True)

        def parse_fault_def(l):
            result = re.findall(r'((?:FAULTY|F)_[^\s]+)', l)
            if len(result) == 0:
                return None

            return result[0]

        with open(fault_seeds_path, 'r') as f:
            faults = list(filter(lambda x: x != None, [
                          parse_fault_def(l) for l in f.readlines()]))

        self.faults = faults
        self.root_path = root_path
        self.seeded_path = seeded_path
        self.output_path = output_path
        self.cov_path = cov_path
        self.test_result_path = test_result_path
        self.fault_map_path = fault_map_path
        self.fault_seeds_path = fault_seeds_path
        self.test_script_path = test_script_path

        self.project_name = project
        self.version = version
        self.current_fault = []

    def run_tests(self, coverage=True, reference_run=False, use_cache=True):
        """
        Run all possible test cases and parse pass/fail result
        """

        logging.info(self.test_script_path)
        _, testsuite = os.path.split(self.test_script_path)
        tc_scripts = get_test_cases(self.test_script_path)

        logging.info(
            f'>> Running test cases of: {testsuite} ({len(tc_scripts)} cases)')
        logging.info(f'{tc_scripts}')

        if reference_run:    # create original output
            assert len(self.current_fault) == 0
            self._freeze_input()

        self._clean_input()
        self._clean_output(update_coverage=(coverage & (not use_cache)))

        cur_dir = os.getcwd()

        errored_tests = []

        for tc in tc_scripts:

            success = False

            retry_count = 0
            while not success:
                command = f'bash ./{tc}'
                os.chdir(self.test_script_path)
                try:
                    p = subprocess.run(shlex.split(command),
                                       stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=10)
                except subprocess.TimeoutExpired as e:
                    p.stderr = b'timeout'

                os.chdir(cur_dir)
                print(p.stdout.decode())
                if len(p.stderr) != 0:
                    logging.warning(f'Error while running `{command}`')
                    logging.warning(p.stderr.decode())
                    errored_tests.append(tc)
                    success = True

                # get coverage data
                if coverage or reference_run:
                    logging.info(f'Collecting coverage: {tc}')
                    success = self._collect_coverage(tc, use_cache=use_cache)
                else:
                    success = True

                retry_count += 1
                if retry_count > 10:
                    raise Exception(
                        'coverage file is not generated with normal run')
                    break

        if reference_run:    # create original output
            ref_output_path = os.path.join(
                self.root_path, f'outputs.{self.version}.orig')
            if os.path.exists(ref_output_path):
                shutil.rmtree(ref_output_path)
            shutil.copytree(self.output_path, ref_output_path)

            # remove output of the execution that didn't generate coverage (original output is segfault)
            tests_with_coverage = [cov_filename[:-5] for cov_filename in os.listdir(os.path.join(self.cov_path, self.fname()))]
            tests_with_output = get_test_cases(ref_output_path)
            tests_with_stderr = [tc_script_name[:-3] for tc_script_name in errored_tests]

            logging.warning(f'errored tests: {tests_with_stderr}')

            tests_to_remove = list((set(tests_with_output) - (set(tests_with_coverage) - set(tests_with_stderr))))
            for testcase in tests_to_remove:
                logging.info(f'removed tests: {testcase}')
                os.remove(os.path.join(ref_output_path, testcase))

        else:
            original_output_path = self.output_path + f'.{self.version}.orig'
            logging.info(
                f'Get pass/fail result by comparing with {original_output_path}')
            ignored_tests, failing_tests = self._get_pass_fail_result(
                original_output_path)

            logging.info(f'failing tests of {self.fname()}: {failing_tests}')

            # Do not consider ignored tests as passing tests - remove coverage files of that runs 
            invalid_original_output_tests = []
            if coverage:
                for testcase in ignored_tests:
                    tc_cov_path = os.path.join(self.cov_path, self.fname(), testcase + '.gcov')
                    if os.path.exists(tc_cov_path):
                        os.remove(tc_cov_path)
                        invalid_original_output_tests.append(testcase)

            if len(self.current_fault) > 0:
                # FIXME: manually omit flaky tests
                if self.project_name == 'gzip':
                    if 'f6' in self.fname():
                        ignored_tests.append('test21')
                        if 'test21' in failing_tests:
                            failing_tests.remove('test21')

                logging.info(f'Saving failing tests: {self.current_fault}')
                if len(invalid_original_output_tests) > 0:
                    logging.warning(f'Ignored tests by removing coverage files: {invalid_original_output_tests}')
                    
                with open(f'{self.test_result_path}/{self.version}_{self.fname()}', 'w') as f:
                    f.writelines([tc + '\n' for tc in failing_tests])

    def _collect_coverage(self, tc_name, use_cache=True):
        if use_cache and os.path.exists(os.path.join(self.cov_path, self.fname(), f'{tc_name[:-3]}.gcov')):
            return True

        # generate gcov file from gcda file
        time.sleep(0.1)
        cov_file_raw = glob.glob(os.path.join(self.seeded_path, '*.gcda'))

        if len(cov_file_raw) == 0:
            for _ in range(10):
                time.sleep(0.1)
                # maybe not generated yet..
                cov_file_raw = glob.glob(
                    os.path.join(self.seeded_path, '*.gcda'))

        if len(cov_file_raw) != 1:
            # coverage file is not generated (segmentation fault / crash on testscript)
            return True

        cov_file_path = cov_file_raw[0]
        _, cov_file_raw = os.path.split(cov_file_raw[0])

        cur_dir = os.getcwd()
        os.chdir(self.seeded_path)

        command = f'gcov {cov_file_raw}'
        print(command)
        p = subprocess.run(shlex.split(command),
                           stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print(p.stdout)
        print(p.stderr)
        if len(p.stderr) != 0:
            os.remove(cov_file_raw)  # reset for next run
            assert not os.path.exists(cov_file_path)
            return False

        os.remove(cov_file_raw)  # reset for next run
        assert not os.path.exists(cov_file_path)

        os.chdir(cur_dir)

        result_lines = p.stdout.decode().split('\n')
        for l in result_lines:
            m = re.search(r'Creating \'(.+\.c\.gcov)\'', l)
            if m != None:
                cov_file = m.group(1)
                print(cov_file)
                break

        shutil.move(os.path.join(self.seeded_path, cov_file),
                    os.path.join(self.cov_path, self.fname(), f'{tc_name[:-3]}.gcov'))
        assert os.path.exists(os.path.join(self.cov_path, self.fname(), f'{tc_name[:-3]}.gcov'))

        return True

    def _get_pass_fail_result(self, original_output_path):
        def is_identical(out1, out2, mode='rt'):
            return out1 == out2

        def read_file(path, mode):
            if mode == 'rt':
                if self.project_name == 'gzip':
                    return open(path, mode, encoding='utf-8').read()
                else:
                    return open(path, mode, encoding='CP949').read()

            elif mode == 'rb':
                return open(path, mode).read()

            else:
                raise Exception(f'not supported file mode: {mode}')

        def get_output_pair(output_path, original_output_path, filename, mode):
            try:
                original_output = read_file(
                    os.path.join(original_output_path, filename), mode)
            except FileNotFoundError as e:
                original_output = None

            except UnicodeDecodeError as e:
                print(e)
                raise Exception(
                    f'UnicodeDecodeError: original output should not have unicode error [{self.version}, {filename}]')

            try:
                faulty_output = read_file(
                    os.path.join(output_path, filename), mode)

            except UnicodeDecodeError as e:
                logging.warning(f'unicode error: {e}')
                faulty_output = 'errored_out'   # should be always different from original output

            except FileNotFoundError as e:
                faulty_output = None

            return original_output, faulty_output

        tests_orig = sort_string_by_number(
            get_test_cases(original_output_path))
        tests = sort_string_by_number(get_test_cases(self.output_path))
        if tests != tests_orig:
            logging.warning(
                f'some test output is missing: {self.version}-{self.fname()}')

        passing_tests = []
        failing_tests = []
        ignored_tests = []
        for test in tests:
            mode = 'rt'
            if is_binary(os.path.join(original_output_path, test)):
                mode = 'rb'

            original_output, faulty_output = get_output_pair(
                self.output_path, original_output_path, test, mode)

            if original_output == None:
                # ignore missing-output tests
                ignored_tests.append(test)
                continue

            test_pass = is_identical(original_output, faulty_output, mode)

            if self.project_name == 'flex' and test_pass:
                # additionally check output file and error file for flex project
                outfile_name = f'out0.{get_test_number(test)}'
                errorfile_name = f'err0.{get_test_number(test)}'

                original_out, faulty_out = get_output_pair(
                    self.output_path, original_output_path, outfile_name, 'rt')

                original_err, faulty_err = get_output_pair(
                    self.output_path, original_output_path, errorfile_name, 'rt')

                test_pass = is_identical(original_out, faulty_out) and is_identical(
                    original_err, faulty_err)

            if test_pass:
                passing_tests.append(test)
            else:
                logging.info(f'\n failing test {test}')
                logging.info(f'original_output: {original_output[:min(100, len(original_output))]}')
                if faulty_output != None:
                    logging.info(f'faulty_output: {faulty_output[:min(100, len(faulty_output))]}')
                else:
                    logging.info('faulty output: None')
                
                failing_tests.append(test)

        logging.warning(f'ignored tests: {ignored_tests}')
        return (ignored_tests, failing_tests)

    def _freeze_input(self):
        if os.path.exists(os.path.join(self.root_path, 'inputs.alt')):
            if len(os.listdir(os.path.join(self.root_path, 'inputs.alt'))) == 0:
                shutil.rmtree(os.path.join(self.root_path, 'inputs.alt'))
                shutil.copytree(os.path.join(self.root_path, 'inputs'),
                                os.path.join(self.root_path, 'inputs.alt'))
        else:
            shutil.copytree(os.path.join(self.root_path, 'inputs'),
                            os.path.join(self.root_path, 'inputs.alt'))

    def _clean_input(self):
        if os.path.exists(os.path.join(self.root_path, 'inputs')):
            shutil.rmtree(os.path.join(self.root_path, 'inputs'))
        shutil.copytree(os.path.join(self.root_path, 'inputs.alt'),
                        os.path.join(self.root_path, 'inputs'))

    def _clean_output(self, update_coverage=False):
        if os.path.exists(self.output_path):
            shutil.rmtree(self.output_path)
        os.mkdir(self.output_path)

        if update_coverage:
            if os.path.exists((os.path.join(self.cov_path, self.fname()))):
                shutil.rmtree(os.path.join(self.cov_path, self.fname()))
            os.makedirs(os.path.join(self.cov_path, self.fname()))

    def get_active_faults(self):
        # check enabled faults by actually looking at FaultSeed.h file
        # should be identical (if not, log warning)
        with open(self.fault_seeds_path, 'r') as f:
            lines = f.readlines()

        faultnames = []
        for i, l in enumerate(lines):
            if 'define' in l and '//' not in l:
                print(l)
                active_fault = re.search(r'define\s([^\s]+)', l).group(1)
                faultnames.append(f'f{self.faults.index(active_fault) + 1}')
                assert active_fault in self.faults

        if set(faultnames) != set(self.current_fault):
            logging.warning(f'Activated faults not matched with actual file')
            logging.warning(f'actual: {faultnames}')
            logging.warning(f'stored: {self.current_fault}')

        return faultnames

    def disable_all_faults(self, compile=False):
        with open(self.fault_seeds_path, 'r') as f:
            lines = f.readlines()

        for i, l in enumerate(lines):
            if '//' not in l and 'define' in l:
                lines[i] = f'// {l}'

        with open(self.fault_seeds_path, 'w') as f:
            f.writelines(lines)

        self.current_fault = []
        if compile:
            self._compile()

    def enable_fault(self, index, compile=True):
        with open(self.fault_seeds_path, 'r') as f:
            lines = f.readlines()

        l = lines[index]
        if '//' in l and 'define' in l:
            logging.info('enabled: ' + re.match(r'//\s(.+)', l).group(1))

            stmt = re.match(r'//\s(.+)', l).group(1) + '\n'

            if '#' not in l:
                stmt = '#' + stmt.lstrip()

            lines[index] = stmt
        else:
            logging.warning(f'not enabled: {l}')

        with open(self.fault_seeds_path, 'w') as f:
            f.writelines(lines)

        self.current_fault.append(f'f{index + 1}')
        if compile:
            self._compile()

    def enable_fault_by_name(self, fault_name, compile=True):
        with open(self.fault_seeds_path, 'r') as f:
            lines = f.readlines()

        for i, l in enumerate(lines):
            if fault_name not in l:
                continue
            if '//' in l:
                print('enabled: ' + re.match(r'//\s(.+)', l).group(1))
                lines[i] = re.match(r'//\s(.+)', l).group(1) + '\n'
                break

    def _compile(self):
        cur_dir = os.getcwd()
        os.chdir(self.seeded_path)
        command = f'make build'
        p = subprocess.run(shlex.split(command),
                           stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        os.chdir(cur_dir)

        print('\n[compile output]')
        print(p.stdout.decode())
        print(p.stderr.decode())

        if len(p.stderr) > 0:
            logging.warning(p.stderr.decode())
            assert 'Error' not in p.stderr.decode()

    def version_id(self):
        return f'{self.project_name}-{self.version}-{self.fname()}'

    def fname(self):
        name = '_'.join(self.current_fault)
        if len(name) == 0:
            return 'orig'

        return name

    def get_fault_combinations(self, fault_num=1):
        def filter_valid_faults(faults, strict=False):
            valid_faults = []   # should contain fault index

            for i in range(len(faults)):
                fault_id = f'f{i+1}'
                valid = True
                try:
                    with open(f'/root/failing_tests/{self.project_name}/{self.version}_{fault_id}') as f:
                        failing_tests = [l.strip() for l in f.readlines()]
                        if len(failing_tests) == 0:
                            valid = False
                    if strict:
                        with open(f'/root/failing_tests/{self.project_name}/{self.version}_{fault_id}.expected') as g:
                            failing_tests_expected = [
                                l.strip() for l in f.readlines()]
                            if set(failing_tests_expected) != set(failing_tests):
                                valid = False
                except FileNotFoundError as e:
                    print(e)
                    print(
                        'Did you forget running single-fault run / parsing GT faultmap?')
                    exit(0)

                if valid:
                    valid_faults.append(i)
            return valid_faults

        # return indices of combined faults by specified fault number
        is_strict = False
        valid_faults = filter_valid_faults(
            self.faults) if fault_num > 1 else range(len(self.faults))
        logging.info(f'All faults in {self.version}: {self.faults}')
        logging.info(f'Valid faults: {valid_faults} (strict: {is_strict})')

        if len(valid_faults) < fault_num:
            print(
                f'Not enough valid faults (with any failing tests) in this version {self.version}')
            logging.warning(
                f'Not enough valid faults (with any failing tests) in this version {self.version}')
            return []

        return list(combinations(valid_faults, fault_num))


def execute(args):
    logging.basicConfig(
        filename=f'logs/execute_{args.project}_{"_".join(args.versions)}_{args.fault_num}.log', filemode='w', level=logging.INFO)
    logging.info(f'all versions from {args.project}: {args.versions}')

    for version in args.versions:
        # versions: [v1, v2, ..]
        v = Version(args.project, version)

        faulty_versions = v.get_fault_combinations(args.fault_num)
        logging.info(f'{version}: apply faults {faulty_versions}')

        if args.faultid != None:
            faults = args.faultid.split('_')
            fault_indices = [int(fault[1:]) - 1 for fault in faults]
            faulty_versions = [fault_indices]

        for faulty_version in faulty_versions:
            v.disable_all_faults()
            for fault_index in list(faulty_version):
                v.enable_fault(fault_index)

            logging.info(f'Fault indices: {faulty_version}')
            logging.info(f'Seeded faults: {v.get_active_faults()}')

            assert len(faulty_version) == len(v.get_active_faults())

            v.run_tests(coverage=args.coverage, use_cache=args.use_cache)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--fault_num', '-n', type=int, default=1)
    parser.add_argument('--coverage', '-c', action='store_true')
    parser.add_argument('--preprocess', action='store_true')
    parser.add_argument('--use_cache', '-u', action='store_true')
    parser.add_argument('--project', '-p', default='gzip')
    parser.add_argument('--versions', '-v', nargs='*')
    parser.add_argument('--faultid')
    args = parser.parse_args()

    versionpath = f'/root/{args.project}/versions.alt/versions.seeded'
    versions = [dirname for dirname in os.listdir(
        versionpath) if os.path.isdir(os.path.join(versionpath, dirname))]

    # if no specific version specified, use all existing versions in a project
    if args.versions == None or len(args.versions) == 0:
        args.versions = versions

    if args.preprocess:
        logging.basicConfig(
        filename=f'logs/execute_{args.project}_{"_".join(args.versions)}_preprocess.log', filemode='w', level=logging.INFO)
        faulty_lines_dict = dict()

        for version in versions:
            split_test_cases(
                f'/root/{args.project}/testplans.alt/test_{version}.sh', args.project)

            v = Version(args.project, version)

            # modify initial SIR project to properly run
            clean_faultseed(v.fault_seeds_path)
            modify_makefile(v.seeded_path, v.project_name)
            add_faultseed_to_source(v.seeded_path, v.project_name)

            # extract faulty locations (line numbers)
            extract_faulty_lines(v, faulty_lines_dict)

            v.disable_all_faults(compile=True)
            v.run_tests(coverage=True, reference_run=True, use_cache=args.use_cache)

        with open(f'/root/faulty_lines/{args.project}_faulty_lines.json', 'w') as f:
            json.dump(faulty_lines_dict, f, indent=4)

        exit(0)

    execute(args)
